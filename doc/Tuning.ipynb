{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Discriminator\n",
    "\n",
    "You can tune the Ringer discriminator on standalone and on the GRID, the latter if you have installed the TuningTools within a, at least, Tier 3 site.\n",
    "\n",
    "In order to run a standalone tuning, you can both run: \n",
    "\n",
    "- [Recommended] [use the executable](#Using-the-tuning-shell-command); or\n",
    "- a [python script](#Running-through-python-script). \n",
    "\n",
    "If you have access to the GRID, you will need to run the [shell command to upload the job](#Running-the-GRID-dispatch-tuning-command).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Standalone\n",
    "\n",
    "Most of the TuningTools functionalities can be accessed through python scripts or a shell command. The executable is the recommended way for running a standalone job.\n",
    "\n",
    "### Using the tuning shell command\n",
    "\n",
    "This is the recommended way for interacting with the tunning job. You will have to specify the configuration you want to use, such as the pre-processing, the Cross-Validation object and the discriminator parameters to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running through python script\n",
    "\n",
    "However, you can directly access the `TuningJob` class, and call it using a python script. The __call__ method documentation cover all available options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method __call__ in module TuningTools.TuningJob:\n",
      "\n",
      "__call__(self, dataLocation, **kw) unbound TuningTools.TuningJob.TuningJob method\n",
      "    Run discrimination tuning for input data created via CreateData.py\n",
      "    Arguments:\n",
      "      - dataLocation: A string containing a path to the data file written\n",
      "        by CreateData.py\n",
      "    Mutually exclusive optional arguments: Either choose the cross (x) or\n",
      "      circle (o) of the following block options.\n",
      "     -------\n",
      "      x crossValid [CrossValid( nSorts=50, nBoxes=10, nTrain=6, nValid=4, \n",
      "                                seed=crossValidSeed )]:\n",
      "        The cross-validation sorts object. The files can be generated using a\n",
      "        CreateConfFiles instance which can be accessed via command line using\n",
      "        the createTuningJobFiles.py script.\n",
      "      x crossValidSeed [None]: Only used when not specifying the crossValid option.\n",
      "        The seed is used by the cross validation random sort generator and\n",
      "        when not specified or specified as None, time is used as seed.\n",
      "      o crossValidFile: The cross-validation file path, pointing to a file\n",
      "        created with the create tuning job files\n",
      "     -------\n",
      "      x confFileList [None]: A python list or a comma separated list of the\n",
      "        root files containing the configuration to run the jobs. The files can\n",
      "        be generated using a CreateConfFiles instance which can be accessed via\n",
      "        command line using the createTuningJobFiles.py script.\n",
      "      o neuronBoundsCol [MatlabLoopingBounds(5,5)]: A LoopingBoundsCollection\n",
      "        range where the the neural network should loop upon.\n",
      "      o sortBoundsCol [PythonLoopingBounds(50)]: A LoopingBoundsCollection\n",
      "        range for the sorts to use from the crossValid object.\n",
      "      o initBoundsCol [PythonLoopingBounds(100)]: A LoopingBoundsCollection\n",
      "        range for the initialization numbers to be ran on this tuning job.\n",
      "        The neuronBoundsCol, sortBoundsCol, initBoundsCol will be synchronously\n",
      "        looped upon, that is, all the first collection information upon those \n",
      "        variables will be used to feed the first job configuration, all of \n",
      "        those second collection information will be used to feed the second job \n",
      "        configuration, and so on...\n",
      "        In the case you have only one job configuration, it can be input as\n",
      "        a single LoopingBounds instance, or values that feed the LoopingBounds\n",
      "        initialization. In the last case, the neuronBoundsCol will be used\n",
      "        to feed a MatlabLoopingBounds, and the sortBoundsCol together with\n",
      "        initBoundsCol will be used to feed a PythonLoopingBounds.\n",
      "        For instance, if you use neuronBoundsCol set to [5,2,11], it will \n",
      "        loop upon the list [5,7,9,11], while if this was set to sortBoundsCol,\n",
      "        it would generate [5,7,9].\n",
      "     -------\n",
      "      x ppFileList [None]: A python list or a comma separated list of the\n",
      "        root files containing the pre-processing chain to apply into \n",
      "        input space and obtain the pattern space. The files can be generated\n",
      "        using a CreateConfFiles instance which is accessed via command\n",
      "        line using the createTuningJobFiles.py script.\n",
      "        The ppFileList must have a file for each of the configuration list \n",
      "        defined, that is, one pre-processing chain for each one of the \n",
      "        neuron/sort/init bounds collection. When only one ppFile is defined and\n",
      "        the configuration list has size greater than one, the pre-processing\n",
      "        chain will be copied for being applied on the other bounds.\n",
      "      o ppCol [PreProcChain( Norm1() )]: A PreProcCollection with the\n",
      "        PreProcChain instances to be applied to each of the configuration\n",
      "        ranges chosen by the above configurations.\n",
      "        The ppCol must have a file for each of the configuration list \n",
      "        defined, that is, one pre-processing chain for each one of the \n",
      "        neuron/sort/init bounds collection. When only one ppFile is defined\n",
      "        and the configuration list has size greater than one, the\n",
      "        pre-processing chain will be copied for being applied on the other\n",
      "        bounds.\n",
      "     -------\n",
      "    Optional arguments:\n",
      "      - compress [True]: Whether to compress file or not.\n",
      "      - doMultiStop (C++ TuningTool prop) [True]: Whether to optimize for SP,\n",
      "          Pf, Pa for the same tuning.\n",
      "      - showEvo (C++ TuningTool prop) [50]: The number of iterations where the\n",
      "          performance is shown.\n",
      "      - maxFail (C++ TuningTool prop) [50]: Maximum number of failures to improve\n",
      "          performance over validation dataset.\n",
      "      - epochs (C++ TuningTool prop) [1000]: Maximum number iterations, where\n",
      "          the tuning algorithm should stop the optimization.\n",
      "      - doPerf (C++ TuningTool prop) [True]: Whether we should run performance\n",
      "          testing under convergence conditions, using test/validation dataset\n",
      "          and estimate operation conditions.\n",
      "      - level [logging.info]: The logging output level.\n",
      "      - seed (C++ TuningTool prop) [None]: The seed to be used by the tuning\n",
      "          algorithm.\n",
      "      - maxFail (C++ TuningTool prop) [50]: Number of epochs which failed to improve\n",
      "          validation efficiency to stop training.\n",
      "      - outputFileBase ['nn.tuned']: The tuning outputFile starting string.\n",
      "          It will also contain a custom string representing the configuration\n",
      "          used to tune the discriminator.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from TuningTools.TuningJob import TuningJob\n",
    "help(TuningJob.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Py.__main__                             INFO Entering main job.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'npConstants' object has no attribute 'fp_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ae9db8f93a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m            \u001b[1;31m#doPerf = True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m            \u001b[1;31m#seed = 0,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m            \u001b[0mppCol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreProcCollection\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mPreProcChain\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mMapStd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m            \u001b[0mcrossValidSeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m66\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m            level = LoggingLevel.DEBUG )\n",
      "\u001b[1;32m/afs/cern.ch/user/w/wsfreund/Ringer/xAODRingerOfflinePorting/RingerTPFrameWork/RootCoreBin/python/TuningTools/PreProc.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mcheckForUnusedVars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnpCurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invRMS\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnpCurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cern.ch/user/w/wsfreund/Ringer/xAODRingerOfflinePorting/RingerTPFrameWork/RootCoreBin/python/RingerCore/npConstants.pyc\u001b[0m in \u001b[0;36mdtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;34m\"Redirect dtype to floating point type.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'npConstants' object has no attribute 'fp_type'"
     ]
    }
   ],
   "source": [
    "# %load ../scripts/skeletons/time_test.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# TODO Improve skeleton documentation\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "DatasetLocationInput = '/afs/cern.ch/work/j/jodafons/public/validate_tuningtool/mc14_13TeV.147406.129160.sgn.offLikelihood.bkg.truth.trig.e24_lhmedium_L1EM20VH_etBin_0_etaBin_0.npz'\n",
    "\n",
    "#try:\n",
    "from RingerCore.Logger import Logger, LoggingLevel\n",
    "mainLogger = Logger.getModuleLogger(__name__)\n",
    "mainLogger.info(\"Entering main job.\")\n",
    "\n",
    "from TuningTools.TuningJob import TuningJob\n",
    "tuningJob = TuningJob()\n",
    "\n",
    "from TuningTools.PreProc import *\n",
    "\n",
    "basepath = '/afs/cern.ch/work/j/jodafons/public'\n",
    "\n",
    "tuningJob( DatasetLocationInput, \n",
    "           neuronBoundsCol = [5, 5], \n",
    "           sortBoundsCol = [0, 2],\n",
    "           initBoundsCol = 2, \n",
    "           #confFileList = basepath + '/user.wsfreund.config.nn5to20_sorts50_1by1_inits100_100by100/job.hn0015.s0040.il0000.iu0099.pic.gz',\n",
    "           #ppFileList = basepath+'/user.wsfreund.Norm1/ppFile_pp_Norm1.pic.gz',\n",
    "           #crossValidFile = basepath+'/user.wsfreund.CrossValid.50Sorts.seed_0/crossValid.pic.gz',\n",
    "           epochs = 5,\n",
    "           showEvo = 1,\n",
    "           algorithmName= 'rprop',\n",
    "           #doMultiStop = True,\n",
    "           #doPerf = True,\n",
    "           #seed = 0,\n",
    "           ppCol = PreProcCollection( PreProcChain( MapStd() ) ),\n",
    "           crossValidSeed = 66,\n",
    "           level = LoggingLevel.DEBUG )\n",
    "\n",
    "mainLogger.info(\"Finished.\")\n",
    "\n",
    "end = timer()\n",
    "\n",
    "print 'execution time is: ', (end - start)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning on the GRID\n",
    "\n",
    "Running the tuning job on the GRID will require more steps. It isn't possible to configure each one of the jobs via the shell, so we will need to create one configuration file for each one of the jobs we will want the GRID to run, as it seems that there is not other way to tell the panda pilot how to divide the job subsets.\n",
    "\n",
    "In order to do so, we will first have to [create the configuration data](#Creating-configuration-data) and afterwards export it to be [available on the GRID](#Exporting-data-to-the-GRID). Only after it will be possible to [dispach the job to the GRID](#Running-the-GRID-dispatch-tuning-command).\n",
    "\n",
    "However, the GRID computational power will make possible to tune the discriminators much faster if the computational effort needed is large :).\n",
    "\n",
    "### Creating configuration data\n",
    "\n",
    "\n",
    "\n",
    "### Exporting data to the GRID\n",
    "\n",
    "### Running the GRID dispatch tuning command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\">\n",
    "    show=true;\n",
    "    function toggle(){\n",
    "        if (show){\n",
    "            $('div.input').hide();\n",
    "        }else{\n",
    "            $('div.input').show();\n",
    "        }\n",
    "        show = !show\n",
    "    }\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "</script>\n",
    "<a href=\"javascript:toggle()\" target=\"_self\"></a>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
